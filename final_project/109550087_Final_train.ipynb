{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:3]:\n        print(os.path.join(dirname, filename))\n    if len(filenames) > 3:\n        print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:16.602276Z","iopub.execute_input":"2023-01-09T16:49:16.603084Z","iopub.status.idle":"2023-01-09T16:49:16.635130Z","shell.execute_reply.started":"2023-01-09T16:49:16.602985Z","shell.execute_reply":"2023-01-09T16:49:16.633982Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-aug-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-aug-2022/train.csv\n/kaggle/input/tabular-playground-series-aug-2022/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install feature-engine\nfrom feature_engine.encoding import WoEEncoder","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-09T16:49:16.637049Z","iopub.execute_input":"2023-01-09T16:49:16.637413Z","iopub.status.idle":"2023-01-09T16:49:32.191403Z","shell.execute_reply.started":"2023-01-09T16:49:16.637379Z","shell.execute_reply":"2023-01-09T16:49:32.190241Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting feature-engine\n  Downloading feature_engine-1.4.0-py2.py3-none-any.whl (276 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: statsmodels>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from feature-engine) (0.13.2)\nRequirement already satisfied: pandas>=1.0.3 in /opt/conda/lib/python3.7/site-packages (from feature-engine) (1.3.5)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from feature-engine) (1.0.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from feature-engine) (1.21.6)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from feature-engine) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.3->feature-engine) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.3->feature-engine) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature-engine) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature-engine) (1.0.1)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.11.1->feature-engine) (22.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.11.1->feature-engine) (0.5.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature-engine) (1.15.0)\nInstalling collected packages: feature-engine\nSuccessfully installed feature-engine-1.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression, HuberRegressor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.193913Z","iopub.execute_input":"2023-01-09T16:49:32.194791Z","iopub.status.idle":"2023-01-09T16:49:32.208946Z","shell.execute_reply.started":"2023-01-09T16:49:32.194726Z","shell.execute_reply":"2023-01-09T16:49:32.207029Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-aug-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-aug-2022/test.csv')\nsubmission = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\n\nprint(\"train\", train.shape)\nprint(\"test\", test.shape)\ndisplay(train.head())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.214081Z","iopub.execute_input":"2023-01-09T16:49:32.215210Z","iopub.status.idle":"2023-01-09T16:49:32.673413Z","shell.execute_reply.started":"2023-01-09T16:49:32.215143Z","shell.execute_reply":"2023-01-09T16:49:32.672007Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train (26570, 26)\ntest (20775, 25)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n0   0            A    80.10  material_7  material_8            9            5   \n1   1            A    84.89  material_7  material_8            9            5   \n2   2            A    82.43  material_7  material_8            9            5   \n3   3            A   101.07  material_7  material_8            9            5   \n4   4            A   188.06  material_7  material_8            9            5   \n\n   measurement_0  measurement_1  measurement_2  ...  measurement_9  \\\n0              7              8              4  ...         10.672   \n1             14              3              3  ...         12.448   \n2             12              1              5  ...         12.715   \n3             13              2              6  ...         12.471   \n4              9              2              8  ...         10.337   \n\n   measurement_10  measurement_11  measurement_12  measurement_13  \\\n0          15.859          17.594          15.193          15.029   \n1          17.947          17.915          11.755          14.732   \n2          15.607             NaN          13.798          16.711   \n3          16.346          18.377          10.020          15.250   \n4          17.082          19.932          12.428          16.182   \n\n   measurement_14  measurement_15  measurement_16  measurement_17  failure  \n0             NaN          13.034          14.684         764.100        0  \n1          15.425          14.395          15.631         682.057        0  \n2          18.631          14.094          17.946         663.376        0  \n3          15.562          16.154          17.172         826.282        0  \n4          12.760          13.153          16.412         579.885        0  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>product_code</th>\n      <th>loading</th>\n      <th>attribute_0</th>\n      <th>attribute_1</th>\n      <th>attribute_2</th>\n      <th>attribute_3</th>\n      <th>measurement_0</th>\n      <th>measurement_1</th>\n      <th>measurement_2</th>\n      <th>...</th>\n      <th>measurement_9</th>\n      <th>measurement_10</th>\n      <th>measurement_11</th>\n      <th>measurement_12</th>\n      <th>measurement_13</th>\n      <th>measurement_14</th>\n      <th>measurement_15</th>\n      <th>measurement_16</th>\n      <th>measurement_17</th>\n      <th>failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A</td>\n      <td>80.10</td>\n      <td>material_7</td>\n      <td>material_8</td>\n      <td>9</td>\n      <td>5</td>\n      <td>7</td>\n      <td>8</td>\n      <td>4</td>\n      <td>...</td>\n      <td>10.672</td>\n      <td>15.859</td>\n      <td>17.594</td>\n      <td>15.193</td>\n      <td>15.029</td>\n      <td>NaN</td>\n      <td>13.034</td>\n      <td>14.684</td>\n      <td>764.100</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A</td>\n      <td>84.89</td>\n      <td>material_7</td>\n      <td>material_8</td>\n      <td>9</td>\n      <td>5</td>\n      <td>14</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>12.448</td>\n      <td>17.947</td>\n      <td>17.915</td>\n      <td>11.755</td>\n      <td>14.732</td>\n      <td>15.425</td>\n      <td>14.395</td>\n      <td>15.631</td>\n      <td>682.057</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A</td>\n      <td>82.43</td>\n      <td>material_7</td>\n      <td>material_8</td>\n      <td>9</td>\n      <td>5</td>\n      <td>12</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>12.715</td>\n      <td>15.607</td>\n      <td>NaN</td>\n      <td>13.798</td>\n      <td>16.711</td>\n      <td>18.631</td>\n      <td>14.094</td>\n      <td>17.946</td>\n      <td>663.376</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>A</td>\n      <td>101.07</td>\n      <td>material_7</td>\n      <td>material_8</td>\n      <td>9</td>\n      <td>5</td>\n      <td>13</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>12.471</td>\n      <td>16.346</td>\n      <td>18.377</td>\n      <td>10.020</td>\n      <td>15.250</td>\n      <td>15.562</td>\n      <td>16.154</td>\n      <td>17.172</td>\n      <td>826.282</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>A</td>\n      <td>188.06</td>\n      <td>material_7</td>\n      <td>material_8</td>\n      <td>9</td>\n      <td>5</td>\n      <td>9</td>\n      <td>2</td>\n      <td>8</td>\n      <td>...</td>\n      <td>10.337</td>\n      <td>17.082</td>\n      <td>19.932</td>\n      <td>12.428</td>\n      <td>16.182</td>\n      <td>12.760</td>\n      <td>13.153</td>\n      <td>16.412</td>\n      <td>579.885</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"      id product_code  loading attribute_0 attribute_1  attribute_2  \\\n0  26570            F   119.57  material_5  material_6            6   \n1  26571            F   113.51  material_5  material_6            6   \n2  26572            F   112.16  material_5  material_6            6   \n3  26573            F   112.72  material_5  material_6            6   \n4  26574            F   208.00  material_5  material_6            6   \n\n   attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n0            4              6              9              6  ...   \n1            4             11              8              0  ...   \n2            4              8             12              4  ...   \n3            4              8             11             10  ...   \n4            4             14             16              8  ...   \n\n   measurement_8  measurement_9  measurement_10  measurement_11  \\\n0         18.654         10.802          15.909          18.070   \n1         19.368         12.032          13.998             NaN   \n2         17.774         11.743          17.046          18.086   \n3         18.948         11.790          18.165          16.163   \n4         19.141         12.370          14.578          17.849   \n\n   measurement_12  measurement_13  measurement_14  measurement_15  \\\n0          13.772          13.659          16.825          13.742   \n1          12.473          17.468          16.708          14.776   \n2          10.907          13.363          15.737          17.065   \n3          10.933          15.501          15.667          12.620   \n4          11.941          16.070          16.183          13.324   \n\n   measurement_16  measurement_17  \n0          17.710         634.612  \n1          14.102         537.037  \n2          16.021         658.995  \n3          16.111         594.301  \n4          17.150         801.044  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>product_code</th>\n      <th>loading</th>\n      <th>attribute_0</th>\n      <th>attribute_1</th>\n      <th>attribute_2</th>\n      <th>attribute_3</th>\n      <th>measurement_0</th>\n      <th>measurement_1</th>\n      <th>measurement_2</th>\n      <th>...</th>\n      <th>measurement_8</th>\n      <th>measurement_9</th>\n      <th>measurement_10</th>\n      <th>measurement_11</th>\n      <th>measurement_12</th>\n      <th>measurement_13</th>\n      <th>measurement_14</th>\n      <th>measurement_15</th>\n      <th>measurement_16</th>\n      <th>measurement_17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26570</td>\n      <td>F</td>\n      <td>119.57</td>\n      <td>material_5</td>\n      <td>material_6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>9</td>\n      <td>6</td>\n      <td>...</td>\n      <td>18.654</td>\n      <td>10.802</td>\n      <td>15.909</td>\n      <td>18.070</td>\n      <td>13.772</td>\n      <td>13.659</td>\n      <td>16.825</td>\n      <td>13.742</td>\n      <td>17.710</td>\n      <td>634.612</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26571</td>\n      <td>F</td>\n      <td>113.51</td>\n      <td>material_5</td>\n      <td>material_6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>11</td>\n      <td>8</td>\n      <td>0</td>\n      <td>...</td>\n      <td>19.368</td>\n      <td>12.032</td>\n      <td>13.998</td>\n      <td>NaN</td>\n      <td>12.473</td>\n      <td>17.468</td>\n      <td>16.708</td>\n      <td>14.776</td>\n      <td>14.102</td>\n      <td>537.037</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26572</td>\n      <td>F</td>\n      <td>112.16</td>\n      <td>material_5</td>\n      <td>material_6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>8</td>\n      <td>12</td>\n      <td>4</td>\n      <td>...</td>\n      <td>17.774</td>\n      <td>11.743</td>\n      <td>17.046</td>\n      <td>18.086</td>\n      <td>10.907</td>\n      <td>13.363</td>\n      <td>15.737</td>\n      <td>17.065</td>\n      <td>16.021</td>\n      <td>658.995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26573</td>\n      <td>F</td>\n      <td>112.72</td>\n      <td>material_5</td>\n      <td>material_6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>8</td>\n      <td>11</td>\n      <td>10</td>\n      <td>...</td>\n      <td>18.948</td>\n      <td>11.790</td>\n      <td>18.165</td>\n      <td>16.163</td>\n      <td>10.933</td>\n      <td>15.501</td>\n      <td>15.667</td>\n      <td>12.620</td>\n      <td>16.111</td>\n      <td>594.301</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26574</td>\n      <td>F</td>\n      <td>208.00</td>\n      <td>material_5</td>\n      <td>material_6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>14</td>\n      <td>16</td>\n      <td>8</td>\n      <td>...</td>\n      <td>19.141</td>\n      <td>12.370</td>\n      <td>14.578</td>\n      <td>17.849</td>\n      <td>11.941</td>\n      <td>16.070</td>\n      <td>16.183</td>\n      <td>13.324</td>\n      <td>17.150</td>\n      <td>801.044</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.676698Z","iopub.execute_input":"2023-01-09T16:49:32.677197Z","iopub.status.idle":"2023-01-09T16:49:32.692690Z","shell.execute_reply.started":"2023-01-09T16:49:32.677149Z","shell.execute_reply":"2023-01-09T16:49:32.691119Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"id                   0\nproduct_code         0\nloading            250\nattribute_0          0\nattribute_1          0\nattribute_2          0\nattribute_3          0\nmeasurement_0        0\nmeasurement_1        0\nmeasurement_2        0\nmeasurement_3      381\nmeasurement_4      538\nmeasurement_5      676\nmeasurement_6      796\nmeasurement_7      937\nmeasurement_8     1048\nmeasurement_9     1227\nmeasurement_10    1300\nmeasurement_11    1468\nmeasurement_12    1601\nmeasurement_13    1774\nmeasurement_14    1874\nmeasurement_15    2009\nmeasurement_16    2110\nmeasurement_17    2284\nfailure              0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.694548Z","iopub.execute_input":"2023-01-09T16:49:32.695167Z","iopub.status.idle":"2023-01-09T16:49:32.708414Z","shell.execute_reply.started":"2023-01-09T16:49:32.695122Z","shell.execute_reply":"2023-01-09T16:49:32.707164Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"id                   0\nproduct_code         0\nloading            223\nattribute_0          0\nattribute_1          0\nattribute_2          0\nattribute_3          0\nmeasurement_0        0\nmeasurement_1        0\nmeasurement_2        0\nmeasurement_3      329\nmeasurement_4      409\nmeasurement_5      508\nmeasurement_6      624\nmeasurement_7      720\nmeasurement_8      846\nmeasurement_9      904\nmeasurement_10    1067\nmeasurement_11    1136\nmeasurement_12    1240\nmeasurement_13    1303\nmeasurement_14    1440\nmeasurement_15    1542\nmeasurement_16    1678\nmeasurement_17    1740\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"measurement_cols = []\nattribute_cols = []\nfor i in train.columns:\n    if \"measurement\" in i:\n        measurement_cols.append(i)\n    elif \"attribute\" in i:\n        attribute_cols.append(i)\n        \nfeat_object = train.select_dtypes(np.object).columns\n        \nprint(measurement_cols)\nprint(attribute_cols)\nprint()\nprint(feat_object)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.710089Z","iopub.execute_input":"2023-01-09T16:49:32.710549Z","iopub.status.idle":"2023-01-09T16:49:32.724525Z","shell.execute_reply.started":"2023-01-09T16:49:32.710517Z","shell.execute_reply":"2023-01-09T16:49:32.723619Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['measurement_0', 'measurement_1', 'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17']\n['attribute_0', 'attribute_1', 'attribute_2', 'attribute_3']\n\nIndex(['product_code', 'attribute_0', 'attribute_1'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"ep = 1.9\nneighbor = 3\n\ndef preprocessing(data):\n    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n\n    # highly correlative features \n    fill_dict = {\n        'A': ['measurement_5','measurement_6','measurement_8'],\n        'B': ['measurement_4','measurement_5','measurement_7'],\n        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n        'I': ['measurement_3','measurement_7','measurement_8']\n    }\n\n    feature = measurement_cols.copy()\n    feature.append('loading')\n\n    for code in data.product_code.unique(): # ABCDEFGHI\n        tmp = data[data.product_code == code]\n        column = fill_dict[code]\n        tmp_train = tmp[column + ['measurement_17']].dropna(how='any')\n        tmp_test = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp['measurement_17'].isnull())]\n\n        regressor = HuberRegressor(epsilon=ep)\n        regressor.fit(tmp_train[column], tmp_train['measurement_17'])\n        data.loc[(data.product_code == code) & (data[column].isnull().sum(axis=1) == 0) \n                 & (data['measurement_17'].isnull()), 'measurement_17'] = regressor.predict(tmp_test[column])\n\n        imputer = KNNImputer(n_neighbors=neighbor)\n        data.loc[data.product_code == code, feature] = imputer.fit_transform(data.loc[data.product_code == code, feature])\n        print(code, \":\", len(tmp_test), \"null samples imputed\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.725703Z","iopub.execute_input":"2023-01-09T16:49:32.726788Z","iopub.status.idle":"2023-01-09T16:49:32.742359Z","shell.execute_reply.started":"2023-01-09T16:49:32.726747Z","shell.execute_reply":"2023-01-09T16:49:32.741226Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"select_feats = [\n    'loading',\n    'attribute_0',\n    'measurement_0',\n    'measurement_1',\n    'measurement_2',\n    'measurement_17',\n    'm3_missing', \n    'm5_missing'\n]\n\n# Select\ndef select(train_df, test_df):\n    train_select = train_df[select_feats]\n    test_select = test_df[select_feats]\n    \n#     display(train_select.head())\n#     display(test_select.head())\n    \n    return train_select, test_select","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.744102Z","iopub.execute_input":"2023-01-09T16:49:32.744624Z","iopub.status.idle":"2023-01-09T16:49:32.759709Z","shell.execute_reply.started":"2023-01-09T16:49:32.744587Z","shell.execute_reply":"2023-01-09T16:49:32.758136Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Encode\ndef encode(train_df, result_df, test_df):\n    woe_encoder = WoEEncoder(variables=['attribute_0'])\n    woe_encoder.fit(train_df, result_df)\n    train_encoded = woe_encoder.transform(train_df)\n    test_encoded = woe_encoder.transform(test_df)\n\n#     display(train_encoded.head())\n#     display(test_encoded.head())\n\n    return train_encoded, test_encoded","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.761349Z","iopub.execute_input":"2023-01-09T16:49:32.761753Z","iopub.status.idle":"2023-01-09T16:49:32.775479Z","shell.execute_reply.started":"2023-01-09T16:49:32.761710Z","shell.execute_reply":"2023-01-09T16:49:32.774180Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Scale\ndef scale(train_df, test_df):\n    scaler = StandardScaler()\n\n    train_scaled = train_df\n    test_scaled = test_df\n\n    train_scaled[select_feats] = scaler.fit_transform(train_df)\n    test_scaled[select_feats] = scaler.transform(test_df)\n\n#     display(train_scaled.head())\n\n    return train_scaled, test_scaled","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.779073Z","iopub.execute_input":"2023-01-09T16:49:32.779823Z","iopub.status.idle":"2023-01-09T16:49:32.787549Z","shell.execute_reply.started":"2023-01-09T16:49:32.779758Z","shell.execute_reply":"2023-01-09T16:49:32.786490Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Concatenate df's\ndata = pd.concat([train, test])\nprint(data.shape)\n\npreprocessing(data)\n\ntrain_processed = data[data.failure.notnull()].copy()\ntest_processed = data[data.failure.isnull()].copy()\ntest_processed = test_processed.drop(['failure'], axis=1)\n\n# display(train_processed.head())\n\ntrain_factor = train_processed.drop(['failure'], axis=1)\ntrain_result = train_processed['failure'].astype(int)\n\ntrain_select, test_select = select(train_factor, test_processed)\n\ntrain_encoded, test_encoded = encode(train_select, train_result, test_select)\n\ntrain_scaled, test_scaled = scale(train_encoded, test_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:32.789239Z","iopub.execute_input":"2023-01-09T16:49:32.789946Z","iopub.status.idle":"2023-01-09T16:49:44.553746Z","shell.execute_reply.started":"2023-01-09T16:49:32.789866Z","shell.execute_reply":"2023-01-09T16:49:44.552602Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(47345, 26)\nA : 386 null samples imputed\nB : 418 null samples imputed\nC : 391 null samples imputed\nD : 398 null samples imputed\nE : 429 null samples imputed\nF : 420 null samples imputed\nG : 373 null samples imputed\nH : 361 null samples imputed\nI : 377 null samples imputed\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm model_skf.sav model_Nkf.sav","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:44.555031Z","iopub.execute_input":"2023-01-09T16:49:44.555372Z","iopub.status.idle":"2023-01-09T16:49:45.648592Z","shell.execute_reply.started":"2023-01-09T16:49:44.555339Z","shell.execute_reply":"2023-01-09T16:49:45.647068Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"rm: cannot remove 'model_skf.sav': No such file or directory\nrm: cannot remove 'model_Nkf.sav': No such file or directory\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Using KFOLD","metadata":{}},{"cell_type":"code","source":"# Train\ny_pred = np.zeros(len(test))\n\nauc = 0\navg_auc = 0\n\nbest_auc = 0\n\nsplits = 5\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n\nfor i, (train_idx, val_idx) in enumerate(skf.split(train_scaled, train_result)):\n    x_train, x_val = train_scaled.iloc[train_idx], train_scaled.iloc[val_idx]\n    y_train, y_val = train_result.iloc[train_idx], train_result.iloc[val_idx]\n    \n    model = LogisticRegression(penalty='l1', solver='liblinear', C=1e-2, class_weight='balanced', max_iter=200, tol=1e-4, n_jobs=-1, random_state=123)\n    model.fit(x_train, y_train)\n\n    val_pred = model.predict_proba(x_val)\n    auc = roc_auc_score(y_val, val_pred[:,1])\n    \n    if (auc > best_auc):\n        best_model = model\n    \n    avg_auc += auc\n    print(\"Fold:\", i + 1, \"auc:\", round(auc, 4))\n    \n#     y_pred += model.predict_proba(test_scaled)[:,1]\n\navg_auc /= splits\n# y_pred /= splits\n\nprint(\"Average auc:\", round(avg_auc, 4))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:45.650090Z","iopub.execute_input":"2023-01-09T16:49:45.651500Z","iopub.status.idle":"2023-01-09T16:49:45.976198Z","shell.execute_reply.started":"2023-01-09T16:49:45.651455Z","shell.execute_reply":"2023-01-09T16:49:45.974398Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Fold: 1 auc: 0.6013\nFold: 2 auc: 0.5922\nFold: 3 auc: 0.5829\nFold: 4 auc: 0.5939\nFold: 5 auc: 0.5855\nAverage auc: 0.5912\n","output_type":"stream"}]},{"cell_type":"code","source":"filename = 'model_skf.sav'\npickle.dump(best_model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:45.979014Z","iopub.execute_input":"2023-01-09T16:49:45.985899Z","iopub.status.idle":"2023-01-09T16:49:45.999175Z","shell.execute_reply.started":"2023-01-09T16:49:45.985813Z","shell.execute_reply":"2023-01-09T16:49:45.997378Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Not Using KFOLD","metadata":{}},{"cell_type":"code","source":"# not using KFold\n\ny_pred = np.zeros(len(test))\nX_train, X_test , y_train , y_test = train_test_split(train_scaled, train_result, test_size=0.2, random_state=123)\n\nmodel = LogisticRegression(penalty='l1', solver='liblinear', C=1e-2, class_weight='balanced',max_iter=200, tol=1e-4, n_jobs=-1, random_state=123)\n\nmodel.fit(X_train[select_feats], y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:46.007319Z","iopub.execute_input":"2023-01-09T16:49:46.008788Z","iopub.status.idle":"2023-01-09T16:49:46.089951Z","shell.execute_reply.started":"2023-01-09T16:49:46.008703Z","shell.execute_reply":"2023-01-09T16:49:46.088780Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(C=0.01, class_weight='balanced', max_iter=200, n_jobs=-1,\n                   penalty='l1', random_state=123, solver='liblinear')"},"metadata":{}}]},{"cell_type":"code","source":"filename = 'model_Nkf.sav'\npickle.dump(model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:49:46.092203Z","iopub.execute_input":"2023-01-09T16:49:46.093439Z","iopub.status.idle":"2023-01-09T16:49:46.099645Z","shell.execute_reply.started":"2023-01-09T16:49:46.093386Z","shell.execute_reply":"2023-01-09T16:49:46.098768Z"},"trusted":true},"execution_count":17,"outputs":[]}]}